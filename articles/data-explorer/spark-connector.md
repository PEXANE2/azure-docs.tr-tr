---
title: Azure Veri Gezgini ve Spark kümeleri arasında veri taşımak için Azure Veri Gezgini bağlayıcısını Apache Spark kullanın.
description: Bu konu başlığı altında, verileri Azure Veri Gezgini ve Apache Spark kümeleri arasında nasıl taşıyacağınız gösterilmektedir.
author: orspod
ms.author: orspodek
ms.reviewer: michazag
ms.service: data-explorer
ms.topic: conceptual
ms.date: 1/14/2020
ms.openlocfilehash: b358287664ac6d6a3b641e1ab63073810ceb4c40
ms.sourcegitcommit: 5192c04feaa3d1bd564efe957f200b7b1a93a381
ms.translationtype: MT
ms.contentlocale: tr-TR
ms.lasthandoff: 03/02/2020
ms.locfileid: "78208633"
---
# <a name="azure-data-explorer-connector-for-apache-spark"></a>Apache Spark için Azure Veri Gezgini Bağlayıcısı

[Apache Spark](https://spark.apache.org/) , büyük ölçekli veri işleme için Birleşik bir analiz altyapısıdır. Azure Veri Gezgini, büyük hacimde veri üzerinde gerçek zamanlı analizler için hızlı ve tam olarak yönetilen bir veri analizi hizmetidir. 

Spark için Azure Veri Gezgini Bağlayıcısı, herhangi bir Spark kümesinde çalışabilen [Açık kaynaklı bir projem](https://github.com/Azure/azure-kusto-spark) . Verileri Azure Veri Gezgini ve Spark kümeleri arasında taşımak için veri kaynağını ve veri havuzunu uygular. Azure Veri Gezgini ve Apache Spark kullanarak, veri odaklı senaryoları hedefleyen hızlı ve ölçeklenebilir uygulamalar oluşturabilirsiniz. Örneğin, Machine Learning (ML), ayıklama-dönüştürme-yükleme (ETL) ve Log Analytics. Bağlayıcısı ile Azure Veri Gezgini, standart Spark kaynağı ve yazma, okuma ve writeStream gibi havuz işlemleri için geçerli bir veri deposu haline gelir.

Azure Veri Gezgini, Batch veya streaming modunda yazabilirsiniz. Azure Veri Gezgini okuma, sütun ayıklama ve koşul push'yi destekler, bu da Azure Veri Gezgini verileri filtreleyerek, aktarılan verilerin hacmini azaltır.

Bu konu başlığı altında, Azure Veri Gezgini Spark bağlayıcısının nasıl yüklenip yapılandırılacağı ve verilerin Azure Veri Gezgini ve Apache Spark kümeleri arasında taşınması açıklanmaktadır.

> [!NOTE]
> Aşağıdaki örneklerden bazıları [Azure Databricks](https://docs.azuredatabricks.net/) Spark kümesine başvurmakla birlikte, Azure Veri Gezgini Spark Bağlayıcısı Databricks veya diğer Spark dağıtımında doğrudan bağımlılıklar almaz.

## <a name="prerequisites"></a>Önkoşullar

* [Azure Veri Gezgini kümesi ve veritabanı oluşturma](/azure/data-explorer/create-cluster-database-portal) 
* Spark kümesi oluşturma
* Azure Veri Gezgini bağlayıcı kitaplığı 'nı yükler:
    * [Spark 2,4, Scala 2,11](https://github.com/Azure/azure-kusto-spark/releases) için önceden oluşturulmuş kitaplıklar 
    * [Maven deposu](https://mvnrepository.com/artifact/com.microsoft.azure.kusto/spark-kusto-connector)
* [Maven 3. x](https://maven.apache.org/download.cgi) yüklendi

> [!TIP]
> 2.3. x sürümleri de desteklenir, ancak Pod. xml bağımlılıklarında bazı değişiklikler gerektirebilir.

## <a name="how-to-build-the-spark-connector"></a>Spark bağlayıcısını oluşturma

> [!NOTE]
> Bu adım isteğe bağlıdır. Önceden oluşturulmuş kitaplıkları kullanıyorsanız [Spark kümesi kurulumuna](#spark-cluster-setup)gidin.

### <a name="build-prerequisites"></a>Derleme önkoşulları

1. Aşağıdaki [kusto Java SDK](/azure/kusto/api/java/kusto-java-client-library) kitaplıklarını içeren [bağımlılıklarda](https://github.com/Azure/azure-kusto-spark#dependencies) listelenen kitaplıkları yükler:
    * [Kusto veri Istemcisi](https://mvnrepository.com/artifact/com.microsoft.azure.kusto/kusto-data)
    * [Kusto ınest Istemcisi](https://mvnrepository.com/artifact/com.microsoft.azure.kusto/kusto-ingest)

1. Spark bağlayıcısını oluşturmak için [Bu kaynağa](https://github.com/Azure/azure-kusto-spark) bakın.

1. Maven proje tanımlarını kullanan Scala/Java uygulamaları için, uygulamanızı aşağıdaki yapıtla bağlayın (en son sürüm farklılık gösterebilir):
    
    ```Maven
       <dependency>
         <groupId>com.microsoft.azure</groupId>
         <artifactId>spark-kusto-connector</artifactId>
         <version>1.1.0</version>
       </dependency>
    ```

### <a name="build-commands"></a>Derleme komutları

Jar oluşturmak ve tüm testleri çalıştırmak için:

```
mvn clean package
```

Jar oluşturmak için tüm testleri çalıştırın ve yerel Maven deponuza jar 'i yüklemek için:

```
mvn clean install
```

Daha fazla bilgi için bkz. [bağlayıcı kullanımı](https://github.com/Azure/azure-kusto-spark#usage).

## <a name="spark-cluster-setup"></a>Spark kümesi kurulumu

> [!NOTE]
> Aşağıdaki adımları gerçekleştirirken en son Azure Veri Gezgini Spark Bağlayıcısı sürümünü kullanmanız önerilir.

1. Spark 2.4.4 ve Scala 2,11 kullanarak Azure Databricks kümesine göre aşağıdaki Spark kümesi ayarlarını yapılandırın:

    ![Databricks kümesi ayarları](media/spark-connector/databricks-cluster.png)
    
1. Maven 'ten en son Spark-kusto-Connector kitaplığını yükler:
    
    ![Içeri aktarma kitaplıklarını](media/spark-connector/db-libraries-view.png) ![Spark-kusto-Connector seçin](media/spark-connector/db-dependencies.png)

1. Tüm gerekli kitaplıkların yüklü olduğunu doğrulayın:

    ![Kitaplıkların yüklü olduğunu doğrulama](media/spark-connector/db-libraries-view.png)

1. JAR dosyası kullanarak yükleme için ek bağımlılıkların yüklendiğini doğrulayın:

    ![Bağımlılık Ekle](media/spark-connector/db-not-maven.png)

## <a name="authentication"></a>Kimlik Doğrulama

Azure Veri Gezgini Spark Bağlayıcısı, aşağıdaki yöntemlerden birini kullanarak Azure Active Directory (Azure AD) ile kimlik doğrulaması yapmanızı sağlar:
* Bir [Azure AD uygulaması](#azure-ad-application-authentication)
* Bir [Azure AD erişim belirteci](https://github.com/Azure/azure-kusto-spark/blob/dev/docs/Authentication.md#direct-authentication-with-access-token)
* [Cihaz kimlik doğrulaması](https://github.com/Azure/azure-kusto-spark/blob/dev/docs/Authentication.md#device-authentication) (üretim dışı senaryolar için)
* Key Vault kaynağına erişmek için bir [Azure Key Vault](https://github.com/Azure/azure-kusto-spark/blob/dev/docs/Authentication.md#key-vault) , Azure-keykasa paketini yükleyip uygulama kimlik bilgilerini sağlayın.

### <a name="azure-ad-application-authentication"></a>Azure AD uygulama kimlik doğrulaması

Azure AD uygulama kimlik doğrulaması, en basit ve en yaygın kimlik doğrulama yöntemidir ve Azure Veri Gezgini Spark Bağlayıcısı için önerilir.

|Özellikler  |Açıklama  |
|---------|---------|
|**KUSTO_AAD_CLIENT_ID**     |   Azure AD uygulaması (istemci) tanımlayıcısı.      |
|**KUSTO_AAD_AUTHORITY_ID**     |  Azure AD kimlik doğrulama yetkilisi. Azure AD dizini (kiracı) KIMLIĞI.        |
|**KUSTO_AAD_CLIENT_PASSWORD**    |    İstemci için Azure AD uygulama anahtarı.     |

### <a name="azure-data-explorer-privileges"></a>Azure Veri Gezgini ayrıcalıkları

Azure Veri Gezgini kümesinde aşağıdaki ayrıcalıkları verin:

* Okuma (veri kaynağı) için Azure AD kimliğinin hedef veritabanında *Görüntüleyici* ayrıcalıklarına veya hedef tablodaki *yönetici* ayrıcalıklarına sahip olması gerekir.
* Yazmak için (veri havuzu), Azure AD kimliğinin hedef veritabanında alma *ayrıcalıklarına sahip olması gerekir* . Ayrıca, yeni tablolar oluşturmak için hedef veritabanında *Kullanıcı* ayrıcalıklarına sahip olmalıdır. Hedef tablo zaten varsa, hedef tabloda *yönetici* ayrıcalıklarını yapılandırmanız gerekir.
 
Azure Veri Gezgini sorumlusu rolleri hakkında daha fazla bilgi için bkz. [rol tabanlı yetkilendirme](/azure/kusto/management/access-control/role-based-authorization). Güvenlik rollerini yönetmek için bkz. [güvenlik rolleri yönetimi](/azure/kusto/management/security-roles).

## <a name="spark-sink-writing-to-azure-data-explorer"></a>Spark havuzu: Azure Veri Gezgini yazma

1. Havuz parametrelerini ayarla:

     ```scala
    val KustoSparkTestAppId = dbutils.secrets.get(scope = "KustoDemos", key = "KustoSparkTestAppId")
    val KustoSparkTestAppKey = dbutils.secrets.get(scope = "KustoDemos", key = "KustoSparkTestAppKey")
 
    val appId = KustoSparkTestAppId
    val appKey = KustoSparkTestAppKey
    val authorityId = "72f988bf-86f1-41af-91ab-2d7cd011db47" // Optional - defaults to microsoft.com
    val cluster = "Sparktest.eastus2"
    val database = "TestDb"
    val table = "StringAndIntTable"
    ```

1. Spark veri çerçevesini Azure Veri Gezgini kümesine Batch olarak yazın:

    ```scala
    import com.microsoft.kusto.spark.datasink.KustoSinkOptions
    import org.apache.spark.sql.{SaveMode, SparkSession}

    df.write
      .format("com.microsoft.kusto.spark.datasource")
      .option(KustoSinkOptions.KUSTO_CLUSTER, cluster)
      .option(KustoSinkOptions.KUSTO_DATABASE, database)
      .option(KustoSinkOptions.KUSTO_TABLE, "Demo3_spark")
      .option(KustoSinkOptions.KUSTO_AAD_CLIENT_ID, appId)
      .option(KustoSinkOptions.KUSTO_AAD_CLIENT_PASSWORD, appKey)
      .option(KustoSinkOptions.KUSTO_AAD_AUTHORITY_ID, authorityId)
      .option(KustoSinkOptions.KUSTO_TABLE_CREATE_OPTIONS, "CreateIfNotExist")
      .mode(SaveMode.Append)
      .save()  
    ```
    
   Ya da Basitleştirilmiş sözdizimini kullanın:
   
    ```scala
         import com.microsoft.kusto.spark.datasink.SparkIngestionProperties
         import com.microsoft.kusto.spark.sql.extension.SparkExtension._
         
         val sparkIngestionProperties = Some(new SparkIngestionProperties()) // Optional, use None if not needed
         df.write.kusto(cluster, database, table, conf, sparkIngestionProperties)
    ```
   
1. Akış verilerini yaz:

    ```scala    
    import org.apache.spark.sql.streaming.Trigger
    import java.util.concurrent.TimeUnit
    import java.util.concurrent.TimeUnit
    import org.apache.spark.sql.streaming.Trigger

    // Set up a checkpoint and disable codeGen. 
    spark.conf.set("spark.sql.streaming.checkpointLocation", "/FileStore/temp/checkpoint")
        
    // Write to a Kusto table from a streaming source
    val kustoQ = df
          .writeStream
          .format("com.microsoft.kusto.spark.datasink.KustoSinkProvider")
          .options(conf) 
          .option(KustoSinkOptions.KUSTO_WRITE_ENABLE_ASYNC, "true") // Optional, better for streaming, harder to handle errors
          .trigger(Trigger.ProcessingTime(TimeUnit.SECONDS.toMillis(10))) // Sync this with the ingestionBatching policy of the database
          .start()
    ```

## <a name="spark-source-reading-from-azure-data-explorer"></a>Spark kaynağı: Azure Veri Gezgini okuma

1. [Küçük miktarlarda veri](/azure/kusto/concepts/querylimits)okurken veri sorgusunu tanımlayın:

    ```scala
    import com.microsoft.kusto.spark.datasource.KustoSourceOptions
    import org.apache.spark.SparkConf
    import org.apache.spark.sql._
    import com.microsoft.azure.kusto.data.ClientRequestProperties

    val query = s"$table | where (ColB % 1000 == 0) | distinct ColA"
    val conf: Map[String, String] = Map(
          KustoSourceOptions.KUSTO_AAD_CLIENT_ID -> appId,
          KustoSourceOptions.KUSTO_AAD_CLIENT_PASSWORD -> appKey
        )

    val df = spark.read.format("com.microsoft.kusto.spark.datasource").
      options(conf).
      option(KustoSourceOptions.KUSTO_QUERY, query).
      option(KustoSourceOptions.KUSTO_DATABASE, database).
      option(KustoSourceOptions.KUSTO_CLUSTER, cluster).
      load()

    // Simplified syntax flavor
    import com.microsoft.kusto.spark.sql.extension.SparkExtension._
    
    val cpr: Option[ClientRequestProperties] = None // Optional
    val df2 = spark.read.kusto(cluster, database, query, conf, cpr)
    display(df2)
    ```

1. İsteğe bağlı: geçici BLOB depolama alanını (Azure Veri Gezgini değil **) sağlarsanız,** Bloblar oluşturulur ve arayanın sorumluluğundadır. Bu, depolamayı sağlamayı, erişim anahtarlarını döndürmeyi ve geçici yapıtları silmeyi içerir. 
    KustoBlobStorageUtils modülü; hesap ve kapsayıcı koordinatlarına ve hesap kimlik bilgilerine göre Blobları silmeye yönelik yardımcı işlevleri veya yazma, okuma ve listeleme izinlerine sahip tam bir SAS URL 'SI içerir. Karşılık gelen RDD 'ye artık gerek duyulmadığında, her işlem geçici blob yapılarını ayrı bir dizinde depolar. Bu dizin, Spark sürücü düğümünde bildirilen okuma işlemi bilgi günlüklerinin bir parçası olarak yakalanır.

    ```scala
    // Use either container/account-key/account name, or container SaS
    val container = dbutils.secrets.get(scope = "KustoDemos", key = "blobContainer")
    val storageAccountKey = dbutils.secrets.get(scope = "KustoDemos", key = "blobStorageAccountKey")
    val storageAccountName = dbutils.secrets.get(scope = "KustoDemos", key = "blobStorageAccountName")
    // val storageSas = dbutils.secrets.get(scope = "KustoDemos", key = "blobStorageSasUrl")
    ```

    Yukarıdaki örnekte Key Vault bağlayıcı arabirimi kullanılarak erişilmez; Databricks gizli dizilerini kullanmanın daha basit bir yöntemi kullanılır.

1. Azure Veri Gezgini okuyun.

    * Geçici BLOB depolama **alanı sağlarsanız Azure** Veri Gezgini ' den aşağıdaki gibi okuyun:

        ```scala
         val conf3 = Map(
              KustoSourceOptions.KUSTO_AAD_CLIENT_ID -> appId,
              KustoSourceOptions.KUSTO_AAD_CLIENT_PASSWORD -> appKey
              KustoSourceOptions.KUSTO_BLOB_STORAGE_SAS_URL -> storageSas)
        val df2 = spark.read.kusto(cluster, database, "ReallyBigTable", conf3)
        
        val dfFiltered = df2
          .where(df2.col("ColA").startsWith("row-2"))
          .filter("ColB > 12")
          .filter("ColB <= 21")
          .select("ColA")
        
        display(dfFiltered)
        ```

    * **Azure Veri Gezgini** geçici BLOB depolama alanı sağlıyorsa Azure Veri Gezgini 'dan aşağıdaki gibi okuyun:
    
        ```scala
        val dfFiltered = df2
          .where(df2.col("ColA").startsWith("row-2"))
          .filter("ColB > 12")
          .filter("ColB <= 21")
          .select("ColA")
        
        display(dfFiltered)
        ```

## <a name="next-steps"></a>Sonraki adımlar

* [Azure Veri Gezgini Spark Bağlayıcısı](https://github.com/Azure/azure-kusto-spark/tree/master/docs) hakkında daha fazla bilgi edinin
* [Java ve Python için örnek kod](https://github.com/Azure/azure-kusto-spark/tree/master/samples/src/main)
